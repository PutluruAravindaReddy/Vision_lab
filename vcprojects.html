<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="./img/srm_logo_round.png" type="image/png">
    <title>Research Projects | Computer Vision Vertical - SRMIST </title>
    <meta property="og:title" content="Research Projects | Computer Vision Vertical - SRMIST">
    <meta property="og:description" content="Computer vision Vertical website SRMIST">
    <meta property="og:image" content="./img/srm_logo_round.png" type="image/png">
    <meta property="og:url" content="https://putluruaravindareddy.github.io/Vision_lab/">
    <meta name="og:site_name" content="Vision_lab">

    <link rel="stylesheet" href="https://pro.fontawesome.com/releases/v5.10.0/css/all.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Bree+Serif&family=Lato&family=Monoton&family=Poppins:wght@400;500&family=Roboto&display=swap"
        rel="stylesheet">
    

    <link rel="stylesheet" href="./navbar.css">
    <link rel="stylesheet" href="vcprojects.css">
</head>

<body>
    <div id="bg">
        <header id="headerbg">
            <img src="./img/srm_logo.svg" alt="" class="srm_logo" height="40">
            <nav id="navbar" class="navbar">
                <ul>
                    <li > <a href="index.html">Home</a> </li>
                    <li> <a href="faculty.html">Faculty</a> </li>
                    <li> <a href="publications.html">Publications</a> </li>
                    <li> <a href="events.html">Events</a> </li>
                    <li> <a href="gallery.html">Gallery</a> </li>
                    <li>
                        <div class="dd-box active vc-css-border">
                            <p>VC Lab</p>
                            <img src="./img/dropdown_arrow.webp" width="18px" height="15px" alt="drop-down arrow">
                        </div>
                        <div class="dd-hide dd-menu ">
                            <a href="vcmembers.html">Members</a>
                            <a href="vcrc.html">VCRC</a>
                            <a href="vcprojects.html">Projects</a>
                            <!-- <a href="vcpublications.html">Publications</a> -->
                            <a href="events.html">Events</a>
                        </div>
                    </li>
                </ul>
            </nav>
            <div id="sidebar" class="sidebar">
                <i class="fas fa-bars"></i>
            </div>
        </header>
        <nav id="navbar2" class="navbar2">
            <ul>
                <li class="active"> <a href="index.html">Home</a> </li>
                <li> <a href="faculty.html">Faculty</a> </li>
                <li> <a href="publications.html">Publications</a> </li>
                <li> <a href="events.html">Events</a> </li>
                <li> <a href="gallery.html">Gallery</a> </li>
                <li>
                    <div class="dd-box">
                        <p>VC Lab</p>
                        <img src="./img/dropdown_arrow.webp" width="18px" alt="drop-down arrow">
                    </div>
                    <div class="dd-hide dd-menu">
                        <a href="vcmembers.html">Members</a>
                        <a href="vcrc.html">VCRC</a>
                        <a href="vcprojects.html">Research</a>
                        <a href="vcpublications.html">Publications</a>
                        <a href="events.html">Events</a>
                    </div>
                </li>
            </ul>
        </nav>

        <section id="hero">

            <h1>VC</h1>
            <h2 id="labText"><span class="visual"></span> </h2>

        </section>
    </div>


    <section id="projects_sec">
        <h1 class=>Human detection in synergy with OSCC detection</h1>
        <div id="projects">
            <div class="carousel-wrapper carousel-1">
                <div class="carousel">
            
                  <img class="carousel__photo initial" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="http://placekitten.com/g/1600/900">
                  <img class="carousel__photo" src="http://placekitten.com/1600/900">
                  
                  <div class="carousel__button--next"></div>
                  <div class="carousel__button--prev"></div>
            
                </div>
            </div>
            <div class="project_div">
                <p><strong>Hardware used : </strong>Microscope and Mi 360° Camera, Oculus Quest 2</p>
                <p><strong>Software used : </strong>Python, Flask </p>
                <p><strong>Problem statement : </strong>creating a synergy of OSCC detection and Human detection using an NLP. </p>
                <p>Pose estimation is a computer vision technique that classifies the different body parts and joints of
                    a human body and tracks their movement. This is achieved by assigning different key-points or
                    ‘landmarks’ to the parts and joints of the body, and thus continuously tracking their real-time
                    location through images or video feed while providing the user with the coordinates of those
                    landmarks.
                    This project made use of Raspberry Pi, more about which will be explained later. The project was
                    made in Python coding language, and the OpenCV and MediaPipe libraries act as the most important
                    parts. The Raspberry Pi camera module was used to get live video input and various other
                    pre-recorded videos were also used to test the project out.
                </p>
            </div>
        </div>
        <h1 class=>Human detection in synergy with OSCC detection</h1>
        <div id="projects">
            <div class="project_div">
                <p><strong>Hardware used : </strong>Microscope and Mi 360° Camera, Oculus Quest 2</p>
                <p><strong>Software used : </strong>Python, Flask </p>
                <p><strong>Problem statement : </strong>creating a synergy of OSCC detection and Human detection using an NLP. </p>
                <p>Pose estimation is a computer vision technique that classifies the different body parts and joints of
                    a human body and tracks their movement. This is achieved by assigning different key-points or
                    ‘landmarks’ to the parts and joints of the body, and thus continuously tracking their real-time
                    location through images or video feed while providing the user with the coordinates of those
                    landmarks.
                    This project made use of Raspberry Pi, more about which will be explained later. The project was
                    made in Python coding language, and the OpenCV and MediaPipe libraries act as the most important
                    parts. The Raspberry Pi camera module was used to get live video input and various other
                    pre-recorded videos were also used to test the project out.
                </p>
            </div>
            <div class="carousel-wrapper carousel-2">
                <div class="carousel">
                
                  <img class="carousel__photo initial" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="http://placekitten.com/g/1600/900">
                  <img class="carousel__photo" src="http://placekitten.com/1600/900">
                  
                  <div class="carousel__button--next"></div>
                  <div class="carousel__button--prev"></div>
            
                </div>
            </div>
        </div>
        <h1 class=>Human detection in synergy with OSCC detection</h1>
        <div id="projects">
            <div class="carousel-wrapper carousel-2">
                <div class="carousel">
                
                  <img class="carousel__photo initial" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="http://placekitten.com/g/1600/900">
                  <img class="carousel__photo" src="http://placekitten.com/1600/900">
                  
                  <div class="carousel__button--next"></div>
                  <div class="carousel__button--prev"></div>
            
                </div>
            </div>
            <div class="project_div">
                <p><strong>Hardware used : </strong>Microscope and Mi 360° Camera, Oculus Quest 2</p>
                <p><strong>Software used : </strong>Python, Flask </p>
                <p><strong>Problem statement : </strong>creating a synergy of OSCC detection and Human detection using an NLP. </p>
                <p>Pose estimation is a computer vision technique that classifies the different body parts and joints of
                    a human body and tracks their movement. This is achieved by assigning different key-points or
                    ‘landmarks’ to the parts and joints of the body, and thus continuously tracking their real-time
                    location through images or video feed while providing the user with the coordinates of those
                    landmarks.
                    This project made use of Raspberry Pi, more about which will be explained later. The project was
                    made in Python coding language, and the OpenCV and MediaPipe libraries act as the most important
                    parts. The Raspberry Pi camera module was used to get live video input and various other
                    pre-recorded videos were also used to test the project out.
                </p>
            </div>
        </div>
        <h1 class=>Human detection in synergy with OSCC detection</h1>
        <div id="projects">
            <div class="project_div">
                <p><strong>Hardware used : </strong>Microscope and Mi 360° Camera, Oculus Quest 2</p>
                <p><strong>Software used : </strong>Python, Flask </p>
                <p><strong>Problem statement : </strong>creating a synergy of OSCC detection and Human detection using an NLP. </p>
                <p>Pose estimation is a computer vision technique that classifies the different body parts and joints of
                    a human body and tracks their movement. This is achieved by assigning different key-points or
                    ‘landmarks’ to the parts and joints of the body, and thus continuously tracking their real-time
                    location through images or video feed while providing the user with the coordinates of those
                    landmarks.
                    This project made use of Raspberry Pi, more about which will be explained later. The project was
                    made in Python coding language, and the OpenCV and MediaPipe libraries act as the most important
                    parts. The Raspberry Pi camera module was used to get live video input and various other
                    pre-recorded videos were also used to test the project out.
                </p>
            </div>
            <div class="carousel-wrapper carousel-2">
                <div class="carousel">
                
                  <img class="carousel__photo initial" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="/img/bg-image.jpg">
                  <img class="carousel__photo" src="http://placekitten.com/g/1600/900">
                  <img class="carousel__photo" src="http://placekitten.com/1600/900">
                  
                  <div class="carousel__button--next"></div>
                  <div class="carousel__button--prev"></div>
            
                </div>
            </div>
        </div>
    </section>

    <section id="footer" class="section-p1">
        <div id="footer-one">
            <div id="footer-image">
                <img href="index.html" src="./img/srm_logo.svg" width="120" height="60" alt="Brand_logo">
            </div>
            <h4>Contact</h4>
            <a href=""><strong>Address : </strong>SRM University ,Tech Park 15th floor</a>
            <a href=""><strong>Phone : </strong>+01 2222 365/(+91) 01 2345 6789 </a>
            <a href=""><strong>Email : </strong>example@gmail.com</a>
            <h4>Follow Us</h4>
            <div id="social-links">
                <i class="fab fa-facebook"></i>
                <i class="fab fa-twitter"></i>
                <i class="fab fa-instagram"></i>
                <i class="fab fa-youtube"></i>
            </div>
        </div>
        <div id="footer-two">
            <iframe
                src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d11999.457313859424!2d80.05174942906093!3d12.821126726594057!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3a52f70ce1c18cd9%3A0xffb39775f24c16e9!2sTech%20Park%20Building!5e0!3m2!1sen!2sin!4v1700621687925!5m2!1sen!2sin"
                width="350" height="200" style="border:0;" allowfullscreen="" loading="lazy"
                referrerpolicy="no-referrer-when-downgrade"></iframe>
        </div>
        <div id="footer-three">
            <h4>About</h4>
            <div class="page-links">
                <a href="#">About Us</a>
                <a href="#">Faculty</a>
                <a href="#">Publications</a>
                <a href="#">Research</a>
                <a href="#">Privacy Policy</a>
                <a href="#">Terms & Conditions</a>
            </div>
        </div>

    </section>
    <div id="copy-right">
        <p>SRM ©2023 - SRM Institute of Science and Technology | All Rights Reserved</p>
    </div>


    <script src="script.js"></script>
</body>

</html>